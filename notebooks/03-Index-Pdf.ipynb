{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Amazon OpenSearch index\n",
    "\n",
    "This notebook demonstrates how to create an Amazon OpenSearch index starting from the PDF document and create embeddings by using GPT-J 6B FP-16 deployed in the previous notebook [02-Deploy-GPT-J-Embeddings](./02-Deploy-GPT-J-Embeddings.ipynb)\n",
    "\n",
    "**SageMaker Studio Kernel**: Data Science 3.0\n",
    "\n",
    "In this exercise you will do:\n",
    " - Use Amazon Textract for generating text files from PDF\n",
    " - Create Amazon OpenSearch index and index documents by using embeddings generater from GPT-J 6B FP-16\n",
    " - Test the end to end solutions by querying documents and generate response by using the two ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install amazon-textract-response-parser amazon-textract-textractor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Step 1 - Import Modules\n",
    "\n",
    "Here weâ€™ll import some libraries and define some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker.session"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:47:42.334271Z",
     "end_time": "2023-06-14T17:47:42.818126Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:47:42.822615Z",
     "end_time": "2023-06-14T17:47:42.900762Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "textract_client = boto3.client(\"textract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create a SageMaker Session and save the default region and the execution role in some Python variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:43:46.102115Z",
     "end_time": "2023-06-13T13:43:46.183980Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:43:46.185209Z",
     "end_time": "2023-06-13T13:43:46.745756Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket_name = sagemaker_session.default_bucket()\n",
    "region = boto3.session.Session().region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2 - Create txt files from unstructured documents\n",
    "\n",
    "Here we are converting different document types, like PDFs and docx, into `.txt` files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s3_input_file_path = \"gen-ai-qa/data/input\"\n",
    "s3_output_file_path = \"gen-ai-qa/data/output\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:43:46.746777Z",
     "end_time": "2023-06-13T13:43:46.749123Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Amazon Textract for extracting text from PDF\n",
    "\n",
    "In this example, we are using the public Amazon Shareholder letter PDF file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:21.235141Z",
     "end_time": "2023-06-14T17:49:21.246573Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_file_path = \"./data/input\"\n",
    "output_file_path = \"./data/output\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:21.376042Z",
     "end_time": "2023-06-14T17:49:21.382338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(input_file_path) if os.path.isfile(os.path.join(input_file_path, f)) and f.endswith(\".pdf\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:22.637166Z",
     "end_time": "2023-06-14T17:49:22.661299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = files[0]\n",
    "\n",
    "file_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:22.944552Z",
     "end_time": "2023-06-14T17:49:22.959734Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upload PDF on S3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_url = sagemaker.Session().upload_data(\n",
    "    os.path.join(input_file_path, file_name),\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=\"/\".join([s3_input_file_path, file_name])\n",
    ")\n",
    "\n",
    "file_url"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:43:48.910714Z",
     "end_time": "2023-06-13T13:43:54.501803Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start an asyncronous job with Amazon Textract"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from textractcaller.t_call import call_textract, Textract_Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = call_textract(\n",
    "    input_document=\"s3://{}/{}\".format(bucket_name, \"/\".join(file_url.split(\"/\")[3:])),\n",
    "    features = [Textract_Features.TABLES],\n",
    "    force_async_api=True,\n",
    "    return_job_id=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:43:54.507346Z",
     "end_time": "2023-06-13T13:43:54.933256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "in_progress = True\n",
    "\n",
    "while in_progress:\n",
    "    response_text = textract_client.get_document_text_detection(\n",
    "        JobId=response[\"JobId\"]\n",
    "    )\n",
    "\n",
    "    if response_text[\"JobStatus\"] == \"IN_PROGRESS\":\n",
    "        print(\"Job {} IN PROGRESS\".format(response[\"JobId\"]))\n",
    "        time.sleep(30)\n",
    "    else:\n",
    "        in_progress = False\n",
    "        print(\"Job {} ended with status {}\".format(response[\"JobId\"], response_text[\"JobStatus\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:43:54.938223Z",
     "end_time": "2023-06-13T13:46:57.026285Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from textractcaller.t_call import get_full_json, Textract_API\n",
    "import traceback\n",
    "from trp import Document"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:47:42.116019Z",
     "end_time": "2023-06-13T13:47:42.133650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_file_path = \"./data/output\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:47:42.328976Z",
     "end_time": "2023-06-13T13:47:42.345621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_text(textract_resp):\n",
    "    try:\n",
    "        doc = Document(textract_resp)\n",
    "\n",
    "        page_number = 1\n",
    "        for page in doc.pages:\n",
    "            print(\"Page \", page_number)\n",
    "\n",
    "            text = \"\"\n",
    "\n",
    "            for line in page.lines:\n",
    "                text = text + \" \" + line.text\n",
    "\n",
    "            # Print tables\n",
    "            for table in page.tables:\n",
    "                text = text + \"\\n\\n\"\n",
    "                for r, row in enumerate(table.rows):\n",
    "                    for c, cell in enumerate(row.cells):\n",
    "                        print(\"Table[{}][{}] = {}\".format(r, c, cell.text))\n",
    "\n",
    "            f = open(\"{}/output_{}.txt\".format(output_file_path, page_number), \"a\")\n",
    "            f.write(text)\n",
    "            page_number +=1\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exception()\n",
    "        print(stacktrace)\n",
    "\n",
    "        raise e"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:47:42.531583Z",
     "end_time": "2023-06-13T13:47:42.536269Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists(output_file_path) and os.path.isdir(output_file_path):\n",
    "    shutil.rmtree(output_file_path)\n",
    "\n",
    "os.mkdir(output_file_path)\n",
    "\n",
    "if response_text[\"JobStatus\"] == \"SUCCEEDED\":\n",
    "\n",
    "    responses = get_full_json(\n",
    "        response[\"JobId\"],\n",
    "        textract_api=Textract_API.ANALYZE,\n",
    "        boto3_textract_client=textract_client\n",
    "    )\n",
    "\n",
    "    write_text(responses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T13:47:43.002216Z",
     "end_time": "2023-06-13T13:48:50.213818Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T12:29:15.894917Z",
     "end_time": "2023-05-03T12:29:17.595766Z"
    }
   },
   "source": [
    "***"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-691148928602/gen-ai-qa/data/input/2022-Shareholder-Letter.pdf/2022-Shareholder-Letter.pdf\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3 - Index documents in Amazon OpenSearch\n",
    "\n",
    "Starting from the text files, we are going to index the documents in OpenSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:14.256368Z",
     "end_time": "2023-06-14T17:49:14.989430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 768\n",
    "output_file_path = \"./data/output\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:15.709900Z",
     "end_time": "2023-06-14T17:49:15.717682Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def doc_iterator(dir_path: str):\n",
    "    for root, _, filenames in os.walk(dir_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            page = filename.split(\".\")[0].split(\"_\")[-1]\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents = file.read()\n",
    "                    yield filename, page, file_contents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:16.075209Z",
     "end_time": "2023-06-14T17:49:16.084471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chunks = []\n",
    "total_passages = 0\n",
    "\n",
    "for doc_name, page, doc in tqdm(doc_iterator(output_file_path)):\n",
    "    n_passages = 0\n",
    "\n",
    "    doc = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", doc)\n",
    "    doc = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", doc)\n",
    "    doc = re.sub(r\"\\n{2,}\", \"\\n\", doc)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "        chunk_overlap=133,\n",
    "    )\n",
    "\n",
    "    tmp_chunks = text_splitter.split_text(doc)\n",
    "\n",
    "    for i, chunk in enumerate(tmp_chunks):\n",
    "        chunks.append({\n",
    "            \"file_name\": file_name,\n",
    "            \"page\": page,\n",
    "            \"passage\": chunk\n",
    "        })\n",
    "        n_passages += 1\n",
    "        total_passages += 1\n",
    "\n",
    "    print(f'Document segmented into {n_passages} passages')\n",
    "\n",
    "print(f'Total passages to index: {total_passages}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:29.696140Z",
     "end_time": "2023-06-14T17:49:30.708352Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create OpenSearch index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:38.042140Z",
     "end_time": "2023-06-14T17:49:38.050078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "es_username = \"bpistone\"\n",
    "es_password = \"7IjarG&%C#\"\n",
    "\n",
    "domain_endpoint = \"https://search-genai-qa-domain-la6ww4ltzdt5rj47ghsuuar2xi.eu-west-1.es.amazonaws.com\"\n",
    "domain_index = \"genai-qa\"\n",
    "\n",
    "URL = f'{domain_endpoint}/{domain_index}'\n",
    "\n",
    "print(es_username)\n",
    "print(es_password)\n",
    "print(URL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:38.356069Z",
     "end_time": "2023-06-14T17:49:38.365500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'settings': {\n",
    "        'index': {\n",
    "            'knn': True  # Enable k-NN search for this index\n",
    "        }\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'embedding': {  # k-NN vector field\n",
    "                'type': 'knn_vector',\n",
    "                'dimension': 4096,  # Dimension of the vector\n",
    "                'similarity': 'cosine'\n",
    "            },\n",
    "            'file_name': {\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'page': {\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'passage': {\n",
    "                'type': 'text'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:38.969974Z",
     "end_time": "2023-06-14T17:49:38.977050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = requests.head(URL, auth=HTTPBasicAuth(es_username, es_password))\n",
    "\n",
    "# If the index does not exist (status code 404), create the index\n",
    "if response.status_code != 404:\n",
    "    print('Index already exists!')\n",
    "    response = requests.delete(URL, auth=HTTPBasicAuth(es_username, es_password))\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "response = requests.put(URL, auth=HTTPBasicAuth(es_username, es_password), json=mapping)\n",
    "print(f'Index created: {response.text}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:39.495552Z",
     "end_time": "2023-06-14T17:49:40.925285Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encode passages (chunks) using JumpStart's GPT-J text embedding model and ingest to OpenSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "endpoint_name_gpt_j = \"gpt-j-qa-endpoint\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:49:40.925996Z",
     "end_time": "2023-06-14T17:49:40.929331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "i = 1\n",
    "for chunk in chunks:\n",
    "    payload = {'text_inputs': [chunk[\"passage\"]]}\n",
    "    payload = json.dumps(payload).encode('utf-8')\n",
    "\n",
    "    response = sagemaker_runtime.invoke_endpoint(EndpointName=endpoint_name_gpt_j,\n",
    "                                                ContentType='application/json',\n",
    "                                                Body=payload)\n",
    "\n",
    "    model_predictions = json.loads(response['Body'].read())\n",
    "    embedding = model_predictions['embedding'][0]\n",
    "\n",
    "    document = {\n",
    "        'embedding': embedding,\n",
    "        'file_name': chunk[\"file_name\"],\n",
    "        'page': chunk[\"page\"],\n",
    "        \"passage\": chunk[\"passage\"]\n",
    "    }\n",
    "\n",
    "    response = requests.post(f'{URL}/_doc/{i}', auth=HTTPBasicAuth(es_username, es_password), json=document)\n",
    "    i += 1\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "    if response.status_code not in [200, 201]:\n",
    "        print(response.status_code)\n",
    "        print(response.text)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T17:50:15.491553Z",
     "end_time": "2023-06-14T18:11:32.514731Z"
    }
   }
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "7830b2e0dcc405ab83456d8c26dd7c2db32ddf1a7b2e64ef505b215ebac66515"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
